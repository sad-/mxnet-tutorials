{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MXNet Optimizer Tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deep learning is used in lots of different practical applications from image classification to machine translation to speech recognition and many more. While, there are different deep neural model architectures for handling these various applications, from Convolutional Neural Networks for image-based tasks or tasks that rely on inputs with local context, to Recurrent Neural Networks for tasks with sequential inputs, one thing remains constant - training a deep learning model requires solving an optimization problem, and this is usually acheived with a gradient descent algorithm that iteratively changes the parameters (or weights) of the deep neural model.\n",
    "\n",
    "Put simply, all supervised deep learning models parametrize a function from inputs to output. In order to learn the value of the parameters, we start with an initialization scheme and iteratively refine the parameter initial values by moving along a direction that is opposite to the (approximate) gradient of the loss function. This functionality is abstracted by the Optimizer API in MXNet. A single step of the model parameter iterative refinement is achieved in MXNet by running `optimizer.step`. This tutorial provides an overview of how to use the various optimizers built-in to MXNet and compares performance across different optimizers on a simple single-layer neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stochastic Gradient Descent\n",
    "The most commonly used gradient descent algorithm for deep learning tasks is a generalization of stochastic gradient descent. Technically, stochastic gradient descent (sgd) refers to an online approximation of the gradient descent algorithm characterized by calculating the gradient of the loss function applied to a single datapoint, instead of your entire dataset and using that to update your parameter values. However, in MXNet, and other deep learning frameworks, the sgd optimizer is agnostic to how many datapoints the loss function is applied to and it is quite common to have the sgd update influenced by a mini-batch loss gradient instead of a single datapoint loss gradient. Furthermore, all other MXNet optimizers are based on sgd, with a modified update step.\n",
    "\n",
    "#### sgd optimizer\n",
    "The sgd optimizer object accepts a construction parameter referred to as the learning rate. This learning rate term is used to determine the step size of the update in the direction of opposite to the calculated gradient of loss function. \n",
    "\n",
    "For sgd with learning rate `lr`, the optimizer.step function performs the single update step:\n",
    "\n",
    "$$w_{i+1} = w_i + lr\\cdot -grad(w_i)$$\n",
    "\n",
    "\n",
    "<p align=\"center\">\n",
    "    <img src=\"sgd_take_six.gif\" alt=\"drawing\"/>\n",
    "</p>\n",
    "\n",
    "\n",
    "#### sgd optimizer with weight decay\n",
    "The sgd update step can be augmented with an extra term to introduce a penalty on the size of the parameters to ensure small weights. Introducing weight decay modifies the objective of the optimization problem implicitly with a regularization term that penalizes large weights.\n",
    "\n",
    "For sgd with learning rate `lr` and weight decay `wd` the optimizer.step function performs the single update step:\n",
    "\n",
    "$$w_{i+1} = w_i + lr\\cdot (-grad(w_i) -\\texttt{wd}\\cdot w_i)$$\n",
    "\n",
    "#### sgd optimizer with momentum\n",
    "The convergence of the sgd optimizer can also be accelerated by momentum. The goal of sgd with momentum is to stabilize the convergence of sgd by improving the approximation of the gradient term by including the gradient terms from previous update steps. In order to achieve this sgd with momentum remembers the update at each iteration to be included in the next iteration and in the equations below we denote the momentum history as $v$. sgd with momentum was introduced by Rumelhart, Hinton and Williams.\n",
    "\n",
    "For the first update the sgd optimizer with momentum performs the single update step:\n",
    "\n",
    "$$ v_1= lr\\cdot -grad(w_0) \\\\\n",
    " w_1= w_0 + v_1 $$\n",
    "\n",
    "For subsequent updates, sgd with momentum with momentum parameter $\\gamma$ performs the update step:\n",
    "\n",
    "$$ v_{i+1} = \\gamma \\cdot v_{i} + lr\\cdot -grad(w_{i}) \\\\$$\n",
    "$$ w_{i+1} = w_i + v_{i+1} $$\n",
    "\n",
    "\n",
    "<p align=\"center\">\n",
    "    <img src=\"momentum_sgd_take_five.gif\" alt=\"drawing\"/>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nesterov Accelerated Stochastic Gradient Descent\n",
    "\n",
    "The momentum method of Nesterov and Nemirovski is a modification to stochastic gradient descent with momentum that allows for faster convergence in practice. With Nesterov Accelerated gradient (nag) descent, the gradient of the loss function is **not** taken with respect to the current parameters as in sgd, but with respect to the refined parameter values after an sgd update step where the current momentum is used as an estimate for the gradient.\n",
    "\n",
    "In other words, with the nag optimizer there are two update steps. The first update step uses the momentum as an approximation of the gradient to derive new values for the weights $(w_i + \\gamma \\cdot v_i)$. The next update step uses the gradient of the loss function with respect to this lookahead parameter value, and the momentum to obtain a new direction and refine our original parameter values.\n",
    "\n",
    "The nag optimizer with momentum parameter $\\gamma$ performs the update step:\n",
    "\n",
    "$$ v_{i+1} = \\gamma \\cdot v_{i} + lr\\cdot -grad(w_{i} + \\gamma \\cdot v_i) \\\\\n",
    "w_{i+1} = w_i + v_{i+1} $$\n",
    "\n",
    "<p align=\"center\">\n",
    "    <img src=\"nesterov_momentum_take_three.gif\" alt=\"drawing\"/>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adaptive Learning Rate Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RMSProp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AdaGrad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
